{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ece9b46-bd51-4840-9d17-f66f26c04221",
   "metadata": {},
   "source": [
    "# Work for 2nd Project Update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8758892-3496-4cf1-ba30-c62157e5e39b",
   "metadata": {},
   "source": [
    "First we'll take the relevant methods from preview_request so we can get the information of any song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664f5379-5f28-43f7-a813-3c66d3d78c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preview_request import preview_request, convert_to_wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7d2699-e8e9-4017-be49-452b239c92a3",
   "metadata": {},
   "source": [
    "We'll need to work with arrays and audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20b9c97-b41b-4266-b410-ae73559fd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a4810-e90f-404e-a0af-1422b02b7406",
   "metadata": {},
   "source": [
    "For some *mild* color manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a13914ce-f10e-4edf-838f-f933117a96ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2a89f2-540e-4f82-ae93-96db3fb30b99",
   "metadata": {},
   "source": [
    "For animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee76f20a-88ae-4f9e-8bf8-bfca11e412e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from manim import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbaefc3-f966-49d3-8083-218a19669b6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of Manim in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf6e307f-831d-4d7d-b963-14922e16c418",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Manim Community <span style=\"color: #008000; text-decoration-color: #008000\">v0.18.1</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Manim Community \u001b[32mv0.\u001b[0m\u001b[32m18.1\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"media/jupyter/RemoveObjectExample@2025-03-03@14-11-37.mp4\" controls autoplay loop style=\"max-width: 60%;\"  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RemoveObjectExample(Scene):\n",
    "    def construct(self):\n",
    "        text = Text(\"Alice and Bob\").scale(3)\n",
    "        self.add(text)\n",
    "        self.wait(3)\n",
    "        self.remove(text)\n",
    "        \n",
    "        # Display the circle\n",
    "        circle = Circle()\n",
    "        self.play(Create(circle))\n",
    "        self.wait(1)\n",
    "        self.remove(circle)\n",
    "\n",
    "%manim -ql -v WARNING RemoveObjectExample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0145d58f-70cb-4806-954f-9c0780d174d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# First Method: Changing Backgrounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab81df6-44e2-4379-92f4-91a90ce4ca69",
   "metadata": {},
   "source": [
    "We'll need to convert from rgb to hex codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1938a26-bda8-42c5-8493-6667fc522cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hex(rgb):\n",
    "    '''\n",
    "    param: tuple of rgb coded colors\n",
    "    returns: hex string\n",
    "    '''\n",
    "    if type(rgb) != tuple:\n",
    "        rgb = tuple(rgb)\n",
    "    return '%02x%02x%02x' % rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a5f2d-c64c-467f-9e56-1f72b8273860",
   "metadata": {},
   "source": [
    "Normalize values between 0-255 for rgb codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88afcb61-3f18-4222-80af-94fdf658beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_for_color(array):\n",
    "    '''\n",
    "    param: np array\n",
    "    returns: np array normalized between 0-255\n",
    "    '''\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    \n",
    "    normalized_array = (array - min_val) / (max_val - min_val) * 255\n",
    "    return normalized_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe9105f-7ce9-47db-895e-7cd886d11645",
   "metadata": {},
   "source": [
    "Here's the driving manim code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "763732f8-e289-4824-9da4-f361bed50ab3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Manim Community <span style=\"color: #008000; text-decoration-color: #008000\">v0.18.1</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Manim Community \u001b[32mv0.\u001b[0m\u001b[32m18.1\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"media/jupyter/colorChanger@2025-03-03@14-18-13.mp4\" controls autoplay loop style=\"max-width: 60%;\"  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class colorChanger(Scene):\n",
    "    def construct(self):\n",
    "        # audio_file_name = preview_request() #for terminal\n",
    "        audio_file_name = \"GMGM_short.wav\"\n",
    "        y, sr = librosa.load(audio_file_name)\n",
    "\n",
    "        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "        \n",
    "        song_time = librosa.get_duration(y=y, sr=sr)\n",
    "        \n",
    "        #Fix last couple seconds\n",
    "        if beat_times[-1] < song_time:\n",
    "            beat_times = np.concatenate((beat_times, np.linspace(beat_times[-1], song_time-0.01, 4)))\n",
    "\n",
    "        percent_through_song = beat_times/song_time\n",
    "\n",
    "\n",
    "        num_to_take_from_y_1 = ((percent_through_song-0.02)*y.size).astype(int)\n",
    "        num_to_take_from_y_2 = ((percent_through_song-0.01)*y.size).astype(int)\n",
    "        num_to_take_from_y_3 = ((percent_through_song+0.00)*y.size).astype(int)\n",
    "\n",
    "        # Normalize the audio values to generate RGB color channels\n",
    "        r = norm_for_color(y[num_to_take_from_y_1]).astype(int)\n",
    "        b = norm_for_color(y[num_to_take_from_y_2]).astype(int)\n",
    "        g = norm_for_color(y[num_to_take_from_y_3]).astype(int)\n",
    "\n",
    "        zip_obj = zip(r,b,g)\n",
    "        color_list = list(zip_obj)\n",
    "\n",
    "        vectorized_function = np.vectorize(rgb_to_hex, signature='(n)->()')\n",
    "        list_of_colors = vectorized_function(np.array(color_list))\n",
    "\n",
    "        cues = np.diff(beat_times)\n",
    "        \n",
    "        self.add_sound(audio_file_name)\n",
    "\n",
    "        for i in range(len(cues)):\n",
    "            text = Text(f\"{beat_times[i]:.2f}\", font_size=144)\n",
    "            self.add(text)  \n",
    "            self.wait(cues[i])\n",
    "\n",
    "            self.camera.background_color = \"#\"+list_of_colors[i]\n",
    "            self.remove(text)\n",
    "            \n",
    "%manim -ql -v WARNING colorChanger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5248a7e4-89e9-4f49-8873-b68c1252fb5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Second Method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7dd73d-bc17-4d59-bc4b-0c2c642b3520",
   "metadata": {},
   "source": [
    "We're going to use this song for the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d75cd284-431b-411c-80fe-e98376520d65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_file_name = \"GMGM_short.wav\"\n",
    "y, sr = librosa.load(\"GMGM_short.wav\")\n",
    "\n",
    "tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "beat_times = librosa.frames_to_time(beat_frames, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccd016-1203-4185-b7f2-212805d0d8dd",
   "metadata": {},
   "source": [
    "To make the visualizations more \"human\" I'll think about the colors in HSV and since manim will accept hex values, we want a way to convert between the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11ddad64-974e-4f31-bed9-a5ce148ed777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_to_hex(hsv):\n",
    "    h, s, v = hsv\n",
    "    #Convert \n",
    "    h = h/360\n",
    "    s = s/100\n",
    "    v = v/100\n",
    "    \n",
    "    # Convert HSV to RGB using colorsys\n",
    "    r, g, b = colorsys.hsv_to_rgb(h, s, v)\n",
    "    \n",
    "    # Convert RGB to HEX\n",
    "    hex_color = '{:02x}{:02x}{:02x}'.format(int(r * 255), int(g * 255), int(b * 255))\n",
    "    \n",
    "    return hex_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c7b18-25cd-455d-a9d1-44a11e96da8b",
   "metadata": {},
   "source": [
    "We'll want a way to normalize a numpy array between 0-n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1594c1ab-1101-443e-8d52-9e9c1adda84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_to_n(array, n=1):\n",
    "    '''\n",
    "    param: np array\n",
    "    returns: np array normalized between 0-n\n",
    "    '''\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    \n",
    "    normalized_array = (array - min_val) / (max_val - min_val) * n\n",
    "    return normalized_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc8b53-d337-45eb-8ca0-acbef120237b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Get *Pitch* for Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "466930f7-db69-455f-978e-25e02d1e7a74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to extract pitch at specific timestamps\n",
    "def extract_max_pitches(y, sr, beat_times, duration=0.1):\n",
    "    pitches = []\n",
    "    for time in beat_times:\n",
    "        # Extract a segment of audio around each timestamp\n",
    "        start_sample = int(time * sr)\n",
    "        end_sample = int((time + duration) * sr)\n",
    "        segment = y[start_sample:end_sample]\n",
    "\n",
    "        # Get pitch\n",
    "        pitches_segment, magnitudes = librosa.core.piptrack(y=segment, sr=sr)\n",
    "        \n",
    "        # Get the maximum pitch from the frame with the highest magnitude\n",
    "        max_pitch = np.max(pitches_segment)\n",
    "        if max_pitch > 0:\n",
    "            pitches.append(max_pitch)\n",
    "        else:\n",
    "            pitches.append(0)  # No pitch detected\n",
    "    \n",
    "    return np.array(pitches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb404c5-455c-4eb3-bb41-74126b0b5858",
   "metadata": {},
   "source": [
    "Let's test out the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "576c74ad-0336-4e21-b76b-c7f4ec1b8b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pitches = extract_max_pitches(y,sr,beat_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f1bf8-7717-4fb8-a824-6ce536323b6a",
   "metadata": {},
   "source": [
    "Notice `beat_times` and `pitches` have the same size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a00e5b72-371f-427d-a2a1-9be124f0e9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20,), (20,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beat_times.shape, pitches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff7654-ebc3-43d4-8798-48223f429cf3",
   "metadata": {},
   "source": [
    "Here's what the `pitches` array looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26c483f3-84c9-4e39-842e-7f2bc5544c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3963.3684, 1911.0146, 1444.118 , 1724.6978, 3501.682 , 3144.96  ,\n",
       "       3505.9402, 2945.83  , 2075.037 , 3667.432 , 3951.5813, 3070.7861,\n",
       "        341.7259, 3996.9146, 2952.812 , 3629.7053, 3993.6128, 2940.2007,\n",
       "       1134.7648, 3683.2927], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca88b9b-0e05-4533-9603-e258882c4acc",
   "metadata": {
    "tags": []
   },
   "source": [
    "And what normalizing will do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84b37fa1-c3fc-422e-ba8b-0be4b9642564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 99,  42,  30,  37,  86,  76,  86,  71,  47,  90,  98,  74,   0,\n",
       "       100,  71,  89,  99,  71,  21,  91])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = norm_to_n(pitches, 100)\n",
    "B.astype(int) #for viewing purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f08d5-5f00-4e8f-a5c9-1e78af0a3834",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2: Get Volume for Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "594d4676-ea41-4190-afcc-b003c054ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract pitch at specific timestamps\n",
    "def extract_max_volume(y, sr, beat_times, duration=0.1):\n",
    "    volumes = []\n",
    "    for time in beat_times:\n",
    "        # Extract a segment of audio around each timestamp\n",
    "        start_sample = int(time * sr)\n",
    "        end_sample = int((time + duration) * sr)\n",
    "        segment = y[start_sample:end_sample]\n",
    "\n",
    "        # Get volume\n",
    "        rms = librosa.feature.rms(y=segment)\n",
    "        rms_db = librosa.amplitude_to_db(rms)\n",
    "        \n",
    "        # Get the maximum volume\n",
    "        max_vol = np.max(rms_db)\n",
    "        volumes.append(max_vol)\n",
    "    \n",
    "    return np.array(volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a17b955-bf19-4682-a7e7-b37bc36ad069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-24.208582, -15.5371  , -13.817259, -12.540924, -14.107727,\n",
       "       -14.334766, -12.101099, -14.683283, -13.998818, -13.993154,\n",
       "       -14.964004, -14.231014, -16.18017 , -13.112265, -17.016418,\n",
       "       -15.444347, -12.484895, -15.126887, -15.156284, -14.447465],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volumes = extract_max_volume(y, sr, beat_times)\n",
    "volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b682988-7ab7-477b-988c-7730c8a5cd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  71,  85,  96,  83,  81, 100,  78,  84,  84,  76,  82,  66,\n",
       "        91,  59,  72,  96,  75,  74,  80])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = norm_to_n(volumes, 100)\n",
    "S.astype(int) #for viewing purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5767f-a105-43a9-8c66-d5f61fcd2633",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: Get Note (within Octave) for Hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "703cd5ba-4c74-4f47-8442-cc3b52bb692a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'A♯', 'F♯', 'A', 'A', 'G', 'A', 'F♯', 'C', 'A♯', 'B', 'G',\n",
       "       'F', 'B', 'F♯', 'A♯', 'B', 'F♯', 'C♯', 'A♯'], dtype='<U2')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes = librosa.hz_to_note(pitches, octave=False)\n",
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "581f85dd-83e6-4a26-9680-2d59d197f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_map = {\n",
    "    'C':1,\n",
    "    'C♯':1.5,\n",
    "    'D':2,\n",
    "    'D♯':2.5,\n",
    "    'E':3,\n",
    "    'F':4,\n",
    "    'F♯':4.5,\n",
    "    'G':5,\n",
    "    'G♯':5.5,\n",
    "    'A':6,\n",
    "    'A♯':5.5,\n",
    "    'B':7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86acfe03-59e5-477a-9b6f-f3cab3a459f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7. , 5.5, 4.5, 6. , 6. , 5. , 6. , 4.5, 1. , 5.5, 7. , 5. , 4. ,\n",
       "       7. , 4.5, 5.5, 7. , 4.5, 1.5, 5.5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_vals = [note_map[note] for note in notes]\n",
    "np.array(note_vals) #made nparray for viewing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d20332dc-a567-42a1-a228-3e768783b616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([360, 270, 210, 300, 300, 240, 300, 210,   0, 270, 360, 240, 180,\n",
       "       360, 210, 270, 360, 210,  30, 270])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = norm_to_n(note_vals,360)\n",
    "H.astype(int)  #for viewing purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03472ca1-9e07-4a15-b932-3430cdd652fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Zip and Colorize!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3441dfbb-1d95-4060-a65f-52845facaed1",
   "metadata": {},
   "source": [
    "As before, we'll zip to make the color channels and colorize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29386ccb-1ce6-40ec-9406-8886315f7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_obj = zip(H,S,B)\n",
    "color_list = list(zip_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30b8ca7-e3a2-480f-b867-bad6ecbfa3f8",
   "metadata": {},
   "source": [
    "Let's look at the first ~10 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac07f419-2531-465c-98ca-709fd3c5fd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(360.0, 0.0, 99.08223),\n",
       " (270.0, 71.62085, 42.93318),\n",
       " (210.0, 85.82563, 30.159649),\n",
       " (300.0, 96.36733, 37.835854),\n",
       " (300.0, 83.426544, 86.45125),\n",
       " (240.0, 81.551346, 76.69191),\n",
       " (300.0, 100.0, 86.56774),\n",
       " (210.0, 78.67283, 71.24404),\n",
       " (0.0, 84.326065, 47.420567),\n",
       " (270.0, 84.37285, 90.98589)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_list[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5485d892-b288-4550-b6ae-ff9b37cad293",
   "metadata": {},
   "source": [
    "Again we'll vectorize the function and apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e294aa9-6557-4980-b722-a885e98306c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fcfcfc', '461f6d', '0a2b4c', '600360', 'dc24dc', '2424c3',\n",
       "       'dc00dc', '266eb5', '781212', '8624e8', 'fb3b3b', '2121be',\n",
       "       '000000', 'ff1515', '4980b6', '923fe5', 'fe0808', '2d71b5',\n",
       "       '37220d', '8b2de9'], dtype='<U6')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_function = np.vectorize(hsv_to_hex, signature='(n)->()')\n",
    "list_of_colors = vectorized_function(np.array(color_list))\n",
    "list_of_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e9c35-6dc7-429a-a9fc-f68454c1d131",
   "metadata": {},
   "source": [
    "## Play!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d802b67-9587-4cde-b3ad-5b44515e72cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Manim Community <span style=\"color: #008000; text-decoration-color: #008000\">v0.18.1</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Manim Community \u001b[32mv0.\u001b[0m\u001b[32m18.1\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PIC16B-25W/lib/python3.11/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=221\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"media/jupyter/hsvAnim@2025-03-03@14-20-28.mp4\" controls autoplay loop style=\"max-width: 60%;\"  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class hsvAnim(Scene):\n",
    "    def construct(self):\n",
    "        # audio_file_name = preview_request()\n",
    "        # y, sr = librosa.load(audio_file_name)\n",
    "        audio_file_name = \"GMGM_30.wav\"\n",
    "        y, sr = librosa.load(\"GMGM_30.wav\")\n",
    "        \n",
    "        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "\n",
    "        song_time = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "        #prevent last 5 sec from being constant\n",
    "        if beat_times[-1] < song_time:\n",
    "            beat_times = np.concatenate((beat_times, np.linspace(beat_times[-1], song_time-0.01, 4)))\n",
    "\n",
    "        note_map = {\n",
    "            'C':1,'C♯':1.5,\n",
    "            'D':2,'D♯':2.5,\n",
    "            'E':3,\n",
    "            'F':4,'F♯':4.5,\n",
    "            'G':5,'G♯':5.5,\n",
    "            'A':6,'A♯':5.5,\n",
    "            'B':7\n",
    "        }\n",
    "\n",
    "\n",
    "        pitches = extract_max_pitches(y, sr, beat_times)\n",
    "        volumes = extract_max_volume(y, sr, beat_times)\n",
    "\n",
    "        notes = librosa.hz_to_note(pitches, octave=False)\n",
    "        note_vals = [note_map[note] for note in notes]\n",
    "\n",
    "        H = norm_to_n(note_vals,360)\n",
    "        S = norm_to_n(volumes, 100)\n",
    "        B = norm_to_n(pitches, 100)\n",
    "\n",
    "\n",
    "        zip_obj = zip(H,S,B)\n",
    "        color_list = list(zip_obj)\n",
    "\n",
    "        vectorized_function = np.vectorize(hsv_to_hex, signature='(n)->()')\n",
    "        list_of_colors = vectorized_function(np.array(color_list))\n",
    "\n",
    "        cues = np.diff(beat_times)\n",
    "        \n",
    "        self.add_sound(audio_file_name)\n",
    "\n",
    "\n",
    "        for i in range(len(cues)):\n",
    "            text = Text(f\"{beat_times[i]:.2f}\", font_size=144)\n",
    "            self.add(text)  \n",
    "            self.wait(cues[i])\n",
    "            self.camera.background_color = \"#\"+list_of_colors[i]\n",
    "            self.remove(text)\n",
    "            \n",
    "        self.wait(3)\n",
    "    \n",
    "%manim -ql -v WARNING hsvAnim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46689872-70c0-416b-9950-76807b97c1ab",
   "metadata": {},
   "source": [
    "# Some Extra Animations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a740b39-a7a6-4017-9094-489dbd21876c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Manim Community <span style=\"color: #008000; text-decoration-color: #008000\">v0.18.1</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Manim Community \u001b[32mv0.\u001b[0m\u001b[32m18.1\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"media/jupyter/ShowingRosePattern@2025-03-03@14-23-19.mp4\" controls autoplay loop style=\"max-width: 60%;\"  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RosePattern(VMobject):\n",
    "    def __init__(self, radius: float = 2, k: float = 3, theta_range=TAU, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.radius = radius\n",
    "        self.k = k\n",
    "\n",
    "        step_size = 0.1\n",
    "        theta = np.arange(0, theta_range + step_size, step_size)\n",
    "\n",
    "        points = [\n",
    "            [\n",
    "                radius * np.cos(k * t) * np.cos(t),\n",
    "                radius * np.cos(k * t) * np.sin(t),\n",
    "                0\n",
    "            ] for t in theta\n",
    "        ]\n",
    "\n",
    "        self.set_points_smoothly(points)\n",
    "        \n",
    "class ShowingRosePattern(Scene):\n",
    "    def construct(self):\n",
    "        self.camera.background_color = '#7fbf26'\n",
    "        rose = RosePattern(k=8, color=RED, stroke_width=15)\n",
    "\n",
    "        self.play(Create(rose), run_time=5)\n",
    "        self.wait()\n",
    "        \n",
    "%manim -ql -v WARNING ShowingRosePattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9807cfb-1c2b-4131-91c0-15bfee3ecf30",
   "metadata": {},
   "source": [
    "# Other Project updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a241c2-ca79-4feb-a174-010f9da33321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
